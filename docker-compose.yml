version: "3.9"

services:
  # ---------------------------------------------------------
  # ðŸ§  Flink JobManager
  # ---------------------------------------------------------
  jobmanager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-jobmanager
    command: ["jobmanager"]

    ports:
      - "8081:8081"

    environment:
      PYTHONPATH: "/opt/flink/app:/opt/flink"

      # Kafka (LOCAL DEV)
      KAFKA_ENDPOINTS: ${KAFKA_ENDPOINTS}
      INPUT_TOPIC: ${INPUT_TOPIC}
      ALERT_TOPIC: ${ALERT_TOPIC}

      TREND_API_BASE_URL: ${TREND_API_BASE_URL}
      TREND_API_TOKEN: ${TREND_API_TOKEN}

      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}

      JOB_MANAGER_RPC_ADDRESS: jobmanager
      TASK_MANAGER_SLOTS: 2
      PARALLELISM: 1

    volumes:
      - ./app:/opt/flink/app:ro
      - ./models:/opt/flink/models
      - flink_logs:/opt/flink/logs

    networks:
      - flink_kafka_net

    restart: always

  # ---------------------------------------------------------
  # âš™ï¸ Flink TaskManager
  # ---------------------------------------------------------
  taskmanager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-taskmanager
    command: ["taskmanager"]

    depends_on:
      - jobmanager

    environment:
      PYTHONPATH: "/opt/flink/app:/opt/flink"

      KAFKA_ENDPOINTS: ${KAFKA_ENDPOINTS}
      INPUT_TOPIC: ${INPUT_TOPIC}
      ALERT_TOPIC: ${ALERT_TOPIC}

      TREND_API_BASE_URL: ${TREND_API_BASE_URL}
      TREND_API_TOKEN: ${TREND_API_TOKEN}

      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}

      JOB_MANAGER_RPC_ADDRESS: jobmanager
      TASK_MANAGER_SLOTS: 2
      PARALLELISM: 1

    volumes:
      - ./app:/opt/flink/app:ro
      - ./models:/opt/flink/models
      - flink_logs:/opt/flink/logs

    networks:
      - flink_kafka_net

    restart: always

  # ---------------------------------------------------------
  # ðŸ”Š Kafka (LOCAL DEV ONLY)
  # ---------------------------------------------------------
  kafka:
    image: confluentinc/cp-kafka:7.5.1
    container_name: kafka

    ports:
      - "9092:9092"

    environment:
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"

      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"

      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"

    volumes:
      - kafka_data:/var/lib/kafka/data

    networks:
      - flink_kafka_net

    restart: always

  # ---------------------------------------------------------
  # ðŸš€ Flink Job Submitter (DEV ONLY)
  # ---------------------------------------------------------
  flink-submit:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-submit

    depends_on:
      - jobmanager
      - taskmanager
      - kafka

    command: >
      bash -c "
        echo 'Waiting for Flink & Kafka...' &&
        sleep 20 &&
        flink run -py /opt/flink/app/main.py \
          --jarfile /opt/flink/lib/flink-connector-kafka-3.2.0-1.19.jar
      "

    environment:
      KAFKA_ENDPOINTS: ${KAFKA_ENDPOINTS}
      INPUT_TOPIC: ${INPUT_TOPIC}
      ALERT_TOPIC: ${ALERT_TOPIC}

    volumes:
      - ./app:/opt/flink/app
      - ./models:/opt/flink/models

    networks:
      - flink_kafka_net

    restart: "no"

# ---------------------------------------------------------
# Network & Volumes
# ---------------------------------------------------------
networks:
  flink_kafka_net:
    driver: bridge

volumes:
  kafka_data:
  flink_logs:

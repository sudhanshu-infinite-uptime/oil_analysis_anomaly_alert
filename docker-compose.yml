version: "3.9"

services:
  # ---------------------------------------------------------
  #  Flink JobManager (AUTO-RUN PIPELINE)
  # ---------------------------------------------------------
  jobmanager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-jobmanager

    command: ["jobmanager"]

    ports:
      - "8081:8081"

    env_file:
      - .env

    environment:
      PYTHONPATH: "/opt/flink/app:/opt/flink"

      # Kafka
      KAFKA_ENDPOINTS: ${KAFKA_ENDPOINTS}
      INPUT_TOPIC: ${INPUT_TOPIC}
      ALERT_TOPIC: ${ALERT_TOPIC}

      # APIs
      TREND_API_BASE_URL: ${TREND_API_BASE_URL}
      TOKEN_URL: ${TOKEN_URL}
      TOKEN_USERNAME: ${TOKEN_USERNAME}
      TOKEN_PASSWORD: ${TOKEN_PASSWORD}
      EXTERNAL_DEVICE_API_BASE_URL: ${EXTERNAL_DEVICE_API_BASE_URL}

      # AWS
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}

      # Flink
      JOB_MANAGER_RPC_ADDRESS: jobmanager
      TASK_MANAGER_SLOTS: 2
      PARALLELISM: 1

    volumes:
      - ./app:/opt/flink/app:ro
      - ./models:/opt/flink/models
      - flink_logs:/opt/flink/logs

    networks:
      - flink_kafka_net

    restart: always

  # ---------------------------------------------------------
  # ⚙️ Flink TaskManager
  # ---------------------------------------------------------
  taskmanager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-taskmanager

    command: ["taskmanager"]

    depends_on:
      - jobmanager

    env_file:
      - .env

    environment:
      PYTHONPATH: "/opt/flink/app:/opt/flink"

      KAFKA_ENDPOINTS: ${KAFKA_ENDPOINTS}
      INPUT_TOPIC: ${INPUT_TOPIC}
      ALERT_TOPIC: ${ALERT_TOPIC}

      TREND_API_BASE_URL: ${TREND_API_BASE_URL}
      TOKEN_URL: ${TOKEN_URL}
      TOKEN_USERNAME: ${TOKEN_USERNAME}
      TOKEN_PASSWORD: ${TOKEN_PASSWORD}
      EXTERNAL_DEVICE_API_BASE_URL: ${EXTERNAL_DEVICE_API_BASE_URL}

      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}

      JOB_MANAGER_RPC_ADDRESS: jobmanager
      TASK_MANAGER_SLOTS: 2
      PARALLELISM: 1

    volumes:
      - ./app:/opt/flink/app:ro
      - ./models:/opt/flink/models
      - flink_logs:/opt/flink/logs

    networks:
      - flink_kafka_net

    restart: always

  # ---------------------------------------------------------
  #  Kafka (LOCAL DEV)
  # ---------------------------------------------------------
  kafka:
    image: confluentinc/cp-kafka:7.5.1
    container_name: kafka

    ports:
      - "9092:9092"

    environment:
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"

      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"

      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"

    volumes:
      - kafka_data:/var/lib/kafka/data

    networks:
      - flink_kafka_net

    restart: always

networks:
  flink_kafka_net:
    driver: bridge

volumes:
  kafka_data:
  flink_logs:









